{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTENTION:\n",
    "\n",
    "1. At the current state, this notebook is mainly a copy of this one form Kaggle: https://www.kaggle.com/jeffd23/catdognet-keras-convnet-starter/notebook\n",
    "2. I am using this as a starting point for future modifications and mainly to learn about data generators for the models\n",
    "3. The model itself will also probably be improved when I have time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, random, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train/'\n",
    "TEST_DIR = 'data/test/'\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
    "train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "# slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\n",
    "train_images = train_dogs[:2000] + train_cats[:2000]\n",
    "random.shuffle(train_images)\n",
    "test_images =  test_images[:25]\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    \n",
    "    return data\n",
    "\n",
    "train = prep_data(train_images)\n",
    "test = prep_data(test_images)\n",
    "\n",
    "print(\"Train shape: {}\".format(train.shape))\n",
    "print(\"Test shape: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in train_images:\n",
    "    if 'dog' in i:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "\n",
    "sns.countplot(labels)\n",
    "plt.title('Cats and Dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cats_and_dogs(idx):\n",
    "    cat = read_image(train_cats[idx])\n",
    "    dog = read_image(train_dogs[idx])\n",
    "    pair = np.concatenate((cat, dog), axis=1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "    \n",
    "for idx in range(0,5):\n",
    "    show_cats_and_dogs(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_avg = np.array([dog[0].T for i, dog in enumerate(train) if labels[i]==1]).mean(axis=0)\n",
    "plt.imshow(dog_avg)\n",
    "plt.title('Your Average Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_avg = np.array([cat[0].T for i, cat in enumerate(train) if labels[i]==0]).mean(axis=0)\n",
    "plt.imshow(cat_avg)\n",
    "plt.title('Your Average Cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "def catdog():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(3, ROWS, COLS), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "#     model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
    "\n",
    "#     model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "#     model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "#     model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = catdog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n",
    "def generate_arrays_from_list(list_images, batch_size=16):\n",
    "    while 1:\n",
    "        count = 0\n",
    "        \n",
    "        batch_imgs = []\n",
    "        y = []\n",
    "        \n",
    "        for i in range(0, batch_size):\n",
    "            img_path = list_images[i]\n",
    "            \n",
    "            i += 1\n",
    "            if (i >= len(list_images)):\n",
    "                i = 0\n",
    "            \n",
    "            if 'dog' in img_path:\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "\n",
    "            batch_imgs.append(list_images[i])\n",
    "        \n",
    "        yield (prep_data(batch_imgs), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb_epoch = 30\n",
    "\n",
    "## Callback for loss logging per epoch\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')        \n",
    "        \n",
    "def run_catdog():\n",
    "        history = LossHistory()\n",
    "        start = time.time()\n",
    "        model.fit_generator(generate_arrays_from_list(train_images_full), \n",
    "                            samples_per_epoch=,\n",
    "                            epochs=nb_epoch,\n",
    "                            callbacks=[history])\n",
    "        print('Fitting took {} seconds'.format(time.time() - start))\n",
    "\n",
    "        predictions = model.predict(test, verbose=0)\n",
    "        return predictions, history\n",
    "\n",
    "predictions, history = run_catdog()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 16\n",
    "\n",
    "## Callback for loss logging per epoch\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')        \n",
    "        \n",
    "def run_catdog():\n",
    "        history = LossHistory()\n",
    "        start = time.time()\n",
    "        model.fit(train, labels, batch_size=batch_size, epochs=nb_epoch,\n",
    "                  validation_split=0.25, verbose=True, shuffle=True, callbacks=[history, early_stopping])\n",
    "        print('Fitting took {} seconds'.format(time.time() - start))\n",
    "\n",
    "        predictions = model.predict(test, verbose=0)\n",
    "        return predictions, history\n",
    "\n",
    "predictions, history = run_catdog()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.losses\n",
    "val_loss = history.val_losses\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,nb_epoch)[0::2])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    if predictions[i, 0] >= 0.5: \n",
    "        print('I am {:.2%} sure this is a Dog'.format(predictions[i][0]))\n",
    "    else: \n",
    "        print('I am {:.2%} sure this is a Cat'.format(1-predictions[i][0]))\n",
    "        \n",
    "    plt.imshow(test[i].T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['/home/apm/Desktop/0.png', '/home/apm/Desktop/2.jpg' ]\n",
    "\n",
    "b = prep_data(a)\n",
    "\n",
    "pred = model.predict(b)\n",
    "\n",
    "for i in range(0, len(pred)):\n",
    "    if pred[i, 0] >= 0.5: \n",
    "        print('I am {:.2%} sure this is a Dog'.format(pred[i][0]))\n",
    "    else: \n",
    "        print('I am {:.2%} sure this is a Cat'.format(1-pred[i][0]))\n",
    "\n",
    "    plt.imshow(b[i].T)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
